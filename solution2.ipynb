{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marco Yu\\anaconda3\\envs\\nlp_20220614\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# !pip install torchtext\n",
    "# !pip install torch\n",
    "import torch\n",
    "from torch import nn\n",
    "import time\n",
    "import torchtext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from collections import defaultdict, Counter\n",
    "import os\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import io\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def init_embeddings(vocab_size, embed_dim, unif):\n",
    "    return np.random.uniform(-unif, unif, (vocab_size, embed_dim))\n",
    "\n",
    "\n",
    "class EmbeddingsReader:\n",
    "\n",
    "    @staticmethod\n",
    "    def from_text(filename, vocab, unif=0.25):\n",
    "\n",
    "        with io.open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            for i, line in enumerate(f):\n",
    "                line = line.rstrip(\"\\n \")\n",
    "                values = line.split(\" \")\n",
    "\n",
    "                if i == 0:\n",
    "                    # fastText style\n",
    "                    if len(values) == 2:\n",
    "                        weight = init_embeddings(len(vocab), values[1], unif)\n",
    "                        continue\n",
    "                    # glove style\n",
    "                    else:\n",
    "                        weight = init_embeddings(len(vocab), len(values[1:]), unif)\n",
    "                word = values[0]\n",
    "                if word in vocab:\n",
    "                    vec = np.asarray(values[1:], dtype=np.float32)\n",
    "                    weight[vocab[word]] = vec\n",
    "        if '[PAD]' in vocab:\n",
    "            weight[vocab['[PAD]']] = 0.0\n",
    "\n",
    "        embeddings = nn.Embedding(weight.shape[0], weight.shape[1])\n",
    "        embeddings.weight = nn.Parameter(torch.from_numpy(weight).float())\n",
    "        return embeddings, weight.shape[1]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_binary(filename, vocab, unif=0.25):\n",
    "        def read_word(f):\n",
    "\n",
    "            s = bytearray()\n",
    "            ch = f.read(1)\n",
    "\n",
    "            while ch != b' ':\n",
    "                s.extend(ch)\n",
    "                ch = f.read(1)\n",
    "            s = s.decode('utf-8')\n",
    "            # Only strip out normal space and \\n not other spaces which are words.\n",
    "            return s.strip(' \\n')\n",
    "\n",
    "        vocab_size = len(vocab)\n",
    "        with io.open(filename, \"rb\") as f:\n",
    "            header = f.readline()\n",
    "            file_vocab_size, embed_dim = map(int, header.split())\n",
    "            weight = init_embeddings(len(vocab), embed_dim, unif)\n",
    "            if '[PAD]' in vocab:\n",
    "                weight[vocab['[PAD]']] = 0.0\n",
    "            width = 4 * embed_dim\n",
    "            for i in range(file_vocab_size):\n",
    "                word = read_word(f)\n",
    "                raw = f.read(width)\n",
    "                if word in vocab:\n",
    "                    vec = np.fromstring(raw, dtype=np.float32)\n",
    "                    weight[vocab[word]] = vec\n",
    "        embeddings = nn.Embedding(weight.shape[0], weight.shape[1])\n",
    "        embeddings.weight = nn.Parameter(torch.from_numpy(weight).float())\n",
    "        return embeddings, embed_dim\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\train.conll\n",
      "data\\dev.conll\n",
      "data\\test.conll\n"
     ]
    }
   ],
   "source": [
    "class Reader:\n",
    "\n",
    "    def __init__(self, files, lowercase=True, min_freq=0, vectorizer=None):\n",
    "        self.vectorizer = vectorizer if vectorizer else self._vectorizer\n",
    "        x = Counter()\n",
    "        y = Counter()\n",
    "        for file_name in files:\n",
    "            if file_name is None:\n",
    "                continue\n",
    "            print(file_name)\n",
    "            df=pd.read_csv(file_name,delimiter='\\t',names=['Word','POS','NP','NER'],skiprows=[0])\n",
    "            df=df.dropna()\n",
    "            x.update(df.Word.to_list())\n",
    "            y.update(df.NER.to_list())\n",
    "\n",
    "        # build vocab\n",
    "        x = dict(filter(lambda cnt: cnt[1] >= min_freq, x.items()))\n",
    "        alpha = list(x.keys())\n",
    "        # alpha.sort()\n",
    "        self.vocab = {w: i+1 for i, w in enumerate(alpha)}\n",
    "        self.vocab['[PAD]'] = 0\n",
    "\n",
    "        self.labels = list(y.keys())\n",
    "        # self.labels.sort()\n",
    "\n",
    "\n",
    "\n",
    "        # self.lowercase = lowercase\n",
    "        # self.tokenizer = tokenizer\n",
    "        # build_vocab = vectorizer is None\n",
    "        # self.vectorizer = vectorizer if vectorizer else self._vectorizer\n",
    "        # x = Counter()\n",
    "        # y = Counter()\n",
    "        # for file_name in files:\n",
    "        #     if file_name is None:\n",
    "        #         continue\n",
    "        #     with open(file_name, encoding='utf-8', mode='r') as f:\n",
    "        #         for line in f:\n",
    "        #             words = line.split()\n",
    "        #             y.update(words[0])\n",
    "        #\n",
    "        #             if build_vocab:\n",
    "        #                 words = self.tokenizer(' '.join(words[1:]))\n",
    "        #                 words = words if not self.lowercase else [w.lower() for w in words]\n",
    "        #                 x.update(words)\n",
    "        # self.labels = list(y.keys())\n",
    "        #\n",
    "        # if build_vocab:\n",
    "        #     x = dict(filter(lambda cnt: cnt[1] >= min_freq, x.items()))\n",
    "        #     alpha = list(x.keys())\n",
    "        #     alpha.sort()\n",
    "        #     self.vocab = {w: i+1 for i, w in enumerate(alpha)}\n",
    "        #     self.vocab['[PAD]'] = 0\n",
    "        #\n",
    "        # self.labels.sort()\n",
    "\n",
    "    def extract_sent(self, df):\n",
    "        sentences=[]\n",
    "        labels=[]\n",
    "        label=[]\n",
    "        sentence=[]\n",
    "        for word,tag in zip(df.Word,df.NER):\n",
    "            label.append(tag)\n",
    "            sentence.append(word)\n",
    "            if word =='.':\n",
    "                labels.append(label)\n",
    "                sentences.append(sentence)\n",
    "                sentence=[]\n",
    "                label=[]\n",
    "        return sentences, labels\n",
    "\n",
    "\n",
    "    def _vectorizer(self, words: List[str]) -> List[int]:\n",
    "        return [self.vocab.get(w, 0) for w in words]\n",
    "\n",
    "    def load(self, filename: str) -> TensorDataset:\n",
    "        label2index = {l: i+1 for i, l in enumerate(self.labels)}\n",
    "        label2index['[PAD]'] = 0\n",
    "        xs = []\n",
    "        lengths = []\n",
    "        ys = []\n",
    "        df=pd.read_csv(filename,delimiter='\\t',names=['Word','POS','NP','NER'],skiprows=[0])\n",
    "        df=df.dropna()\n",
    "        sentences, label_sets=self.extract_sent(df)\n",
    "\n",
    "        for sentence, label_set in zip(sentences,label_sets):\n",
    "            ys.append(torch.tensor(list(label2index[label] for label in label_set), dtype=torch.long))\n",
    "            words=sentence # just remind that sentence are already list of words\n",
    "            vec = self.vectorizer(words)\n",
    "            lengths.append(len(vec))\n",
    "            xs.append(torch.tensor(vec, dtype=torch.long))\n",
    "        x_tensor = torch.nn.utils.rnn.pad_sequence(xs, batch_first=True)\n",
    "        lengths_tensor = torch.tensor(lengths, dtype=torch.long)\n",
    "        y_tensor= torch.nn.utils.rnn.pad_sequence(ys, batch_first=True)\n",
    "        # y_tensor q= torch.tensor(ys, dtype=torch.long)\n",
    "        return TensorDataset(x_tensor, lengths_tensor, y_tensor)\n",
    "BASE = 'data'\n",
    "TRAIN=os.path.join(BASE, 'train.conll')\n",
    "VALID=os.path.join(BASE,'dev.conll')\n",
    "TEST=os.path.join(BASE,'test.conll')\n",
    "r=Reader((TRAIN,VALID,TEST))\n",
    "train = r.load(TRAIN)\n",
    "valid=r.load(VALID)\n",
    "test=r.load(TEST)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "PRETRAINED_EMBEDDINGS_FILE='word_embedding/glove.6B.50d/glove.6B.50d.txt'\n",
    "embeddings, embed_dim = EmbeddingsReader.from_text(PRETRAINED_EMBEDDINGS_FILE, r.vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embeddings, num_classes, embed_dim, rnn_units,tag_to_ix,batch_size, rnn_layers=1, dropout=0.1, hidden_units=[]):\n",
    "        super().__init__()\n",
    "        # self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = rnn_units\n",
    "        # self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix # dictionary of tags\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        self.batch_size=batch_size\n",
    "\n",
    "        self.embeddings=embeddings\n",
    "        self.lstm = nn.LSTM(embed_dim, rnn_units // 2,\n",
    "                        num_layers=1, bidirectional=True)\n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(rnn_units, self.tagset_size)\n",
    "\n",
    "        # Matrix of transition parameters.  Entry i,j is the score of\n",
    "        # transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(\n",
    "        torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, self.batch_size, self.hidden_dim // 2),\n",
    "                torch.randn(2, self.batch_size, self.hidden_dim // 2))\n",
    "\n",
    "\n",
    "        # self.embeddings=embeddings\n",
    "        # self.dropout=nn.Dropout(dropout)\n",
    "        # self.rnn=nn.LSTM(embed_dim,rnn_units,\n",
    "        #                  num_layers=rnn_layers,\n",
    "        #                  dropout=dropout,\n",
    "        #                  bidirectional=False,\n",
    "        #                  batch_first=False)\n",
    "        #\n",
    "        # nn.init.orthogonal_(self.rnn.weight_hh_l0)\n",
    "        # nn.init.orthogonal_(self.rnn.weight_ih_l0)\n",
    "        #\n",
    "        # # build hidden layers\n",
    "        # sequence=[]\n",
    "        # input_units=rnn_units\n",
    "        # output_units=rnn_units\n",
    "        # for h in hidden_units:\n",
    "        #     sequence.append(nn.Linear(input_units,h))\n",
    "        #     input_units=h\n",
    "        #     output_units=h\n",
    "        #\n",
    "        # sequence.append(nn.Linear(output_units,num_classes)) # add final classifier layer\n",
    "        # self.outputs=nn.Sequential(*sequence) # create sequential model for every hidden layer\n",
    "    def _forward_alg(self, feats):\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # broadcast the emission score: it is the same regardless of\n",
    "                # the previous tag\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size)\n",
    "                # the ith entry of trans_score is the score of transitioning to\n",
    "                # next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the\n",
    "                # scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, inputs):\n",
    "        one_hots, lengths = inputs\n",
    "        self.hidden = self.init_hidden()\n",
    "        # embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        embeds=self.embeddings(one_hots)\n",
    "        embeds=embeds.transpose(0,1)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embeds, lengths.tolist())\n",
    "        lstm_out, hidden = self.lstm(packed, self.hidden)\n",
    "        # print(lstm_out.shape())\n",
    "        lstm_outs, lstm_outs_lengths=torch.nn.utils.rnn.pad_packed_sequence(lstm_out)\n",
    "        # lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "        lstm_feats = self.hidden2tag(lstm_outs)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags]) # Add START_TAG ahead of the origin tags\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, inputs, tags):\n",
    "        feats = self._get_lstm_features(inputs)\n",
    "\n",
    "        feats=feats.view(-1,self.tagset_size)\n",
    "\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, inputs):  # dont confuse this with _forward_alg above.\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(inputs)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def process_bar(num, total):\n",
    "    rate = float(num) / total\n",
    "    ratenum = int(100 * rate)\n",
    "    r = '\\rModel training:[{}{}]{}%'.format('*' * ratenum, ' ' * (100 - ratenum), ratenum)\n",
    "    sys.stdout.write(r)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self,optimizer:torch.optim.Optimizer):\n",
    "        self.optimizer=optimizer\n",
    "        pass\n",
    "\n",
    "    def run(self,model, train, loss, batch_size,labels,optimizer=None):\n",
    "        model.train()\n",
    "        self.optimizer= optimizer if optimizer else self.optimizer\n",
    "        cm=ConfusionMatrix(labels)\n",
    "\n",
    "        train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        log_interval = int(len(train_loader) * 0.01)\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "\n",
    "            loss_value, y_pred, y_actual = self.update(model, loss, batch,self.optimizer)\n",
    "            # _, best = y_pred.max(1)\n",
    "            yt = y_actual.cpu().int().numpy()\n",
    "            yp = y_pred.cpu().int().numpy()\n",
    "            cm.add_batch(yt,yp)\n",
    "            if batch_idx % log_interval == 0:  # 根据设置的显式间隔输出训练日志\n",
    "                process_bar(batch_idx, len(train_loader))\n",
    "\n",
    "        print(cm.get_all_metrics())\n",
    "        return cm\n",
    "\n",
    "    def update(self,model, loss, batch, optimizer):\n",
    "            optimizer.zero_grad()\n",
    "            x, lengths, y = batch\n",
    "            # print(batch)\n",
    "            lengths, perm_idx = lengths.sort(0, descending=True)\n",
    "            x_sorted = x[perm_idx]\n",
    "            y_sorted = y[perm_idx]\n",
    "            # print(x_sorted,lengths,y_sorted)\n",
    "            device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            y_sorted = y_sorted.to(device)\n",
    "            inputs = (x_sorted.to(device), lengths)\n",
    "            # print(inputs)\n",
    "            y_pred = model(inputs)\n",
    "\n",
    "            mask = (y_sorted != 0)\n",
    "            valid = (mask.sum(dim=1))\n",
    "            y_sorted=y_sorted[mask].split(valid.tolist())[0]\n",
    "\n",
    "            y_sorted=np.array(y_sorted).tolist()\n",
    "            y_sorted=torch.tensor(y_sorted, dtype=torch.long)\n",
    "            y_pred=(torch.tensor(y_pred[1], dtype=torch.long))\n",
    "            loss_value=model.neg_log_likelihood(inputs, y_sorted)\n",
    "            # loss_value = loss(torch.tensor(y_pred[1],dtype= torch.long), torch.tensor(y_sorted,dtype= torch.long))\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            return loss_value.item(), y_pred, y_sorted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def run(self,model, dataset, labels, batch_size=1):\n",
    "        model.train()\n",
    "\n",
    "        cm=ConfusionMatrix(labels)\n",
    "\n",
    "        train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        log_interval = int(len(train_loader) * 0.01)\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "\n",
    "            y_pred, y_actual = self.inference(model, batch)\n",
    "            # _, best = y_pred.max(1)\n",
    "            yt = y_actual.cpu().int().numpy()\n",
    "            yp = y_pred.cpu().int().numpy()\n",
    "            cm.add_batch(yt,yp)\n",
    "            # if batch_idx % log_interval == 0:  # 根据设置的显式间隔输出训练日志\n",
    "            #     process_bar(batch_idx, len(train_loader))\n",
    "\n",
    "        print(cm.get_all_metrics())\n",
    "        return cm\n",
    "\n",
    "    def inference(self, model, batch):\n",
    "        with torch.no_grad():\n",
    "            x, lengths, y = batch\n",
    "            lengths, perm_idx = lengths.sort(0, descending=True)\n",
    "            x_sorted = x[perm_idx]\n",
    "            y_sorted = y[perm_idx]\n",
    "            device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            y_sorted = y_sorted.to(device)\n",
    "            inputs = (x_sorted.to(device), lengths)\n",
    "            y_pred = model(inputs)\n",
    "\n",
    "            mask = (y_sorted != 0)\n",
    "            valid = (mask.sum(dim=1))\n",
    "            y_sorted=y_sorted[mask].split(valid.tolist())[0]\n",
    "\n",
    "            y_sorted=np.array(y_sorted).tolist()\n",
    "            y_sorted=torch.tensor(y_sorted, dtype=torch.long)\n",
    "            y_pred=(torch.tensor(y_pred[1], dtype=torch.long))\n",
    "\n",
    "            return y_pred, y_sorted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def fit(model, labels, optimizer, loss, epochs, batch_size, train, valid, test):\n",
    "\n",
    "    trainer = Trainer(optimizer)\n",
    "    evaluator = Evaluator()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('EPOCH {}'.format(epoch + 1))\n",
    "        print('=================================')\n",
    "        print('Training Results')\n",
    "        cm = trainer.run(model, labels=labels, train=train, loss=loss, batch_size=batch_size)\n",
    "        print('Validation Results')\n",
    "        cm = evaluator.run(model,valid,labels=labels)\n",
    "        print(cm.get_all_metrics())\n",
    "        if cm.get_acc() > best_acc:\n",
    "            print('New best model {:.2f}'.format(cm.get_acc()))\n",
    "            best_acc = cm.get_acc()\n",
    "            torch.save(model.state_dict(), './checkpoint.pth')\n",
    "    if test:\n",
    "        model.load_state_dict(torch.load('./checkpoint.pth'))\n",
    "        cm = evaluator.run(model,valid,labels=labels)\n",
    "        print('Final result')\n",
    "        print(cm.get_all_metrics())\n",
    "    return cm.get_acc()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 1556556 parameters\n",
      "EPOCH 1\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[                                                                                                    ]0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marco Yu\\AppData\\Local\\Temp\\ipykernel_22924\\3123264233.py:19: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  self._cm = np.zeros((nc, nc), dtype=np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.8220400186923829, 'mean_precision': 0.23693003912972874, 'mean_recall': 0.16282344034556204, 'macro_f1': 0.17860746385353918, 'weighted_precision': 0.7712630012247131, 'weighted_recall': 0.8220400186923829, 'weighted_f1': 0.786474760018041}\n",
      "Validation Results\n",
      "{'acc': 0.8660948437345953, 'mean_precision': 0.3081198007606099, 'mean_recall': 0.22011041092229652, 'macro_f1': 0.23577878971062693, 'weighted_precision': 0.8210817840130403, 'weighted_recall': 0.8660948437345953, 'weighted_f1': 0.835268242121525}\n",
      "{'acc': 0.8660948437345953, 'mean_precision': 0.3081198007606099, 'mean_recall': 0.22011041092229652, 'macro_f1': 0.23577878971062693, 'weighted_precision': 0.8210817840130403, 'weighted_recall': 0.8660948437345953, 'weighted_f1': 0.835268242121525}\n",
      "New best model 0.87\n",
      "EPOCH 2\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.8980840307574663, 'mean_precision': 0.40775136943076634, 'mean_recall': 0.33172889002186473, 'macro_f1': 0.343563908754956, 'weighted_precision': 0.8744855275886607, 'weighted_recall': 0.8980840307574663, 'weighted_f1': 0.8808728554492279}\n",
      "Validation Results\n",
      "{'acc': 0.8891057872424332, 'mean_precision': 0.40233940079067704, 'mean_recall': 0.32999221955412755, 'macro_f1': 0.33481967295642684, 'weighted_precision': 0.873500751395146, 'weighted_recall': 0.8891057872424332, 'weighted_f1': 0.8751229677816473}\n",
      "{'acc': 0.8891057872424332, 'mean_precision': 0.40233940079067704, 'mean_recall': 0.32999221955412755, 'macro_f1': 0.33481967295642684, 'weighted_precision': 0.873500751395146, 'weighted_recall': 0.8891057872424332, 'weighted_f1': 0.8751229677816473}\n",
      "New best model 0.89\n",
      "EPOCH 3\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9395046518543694, 'mean_precision': 0.553080516202615, 'mean_recall': 0.49016877969247896, 'macro_f1': 0.5094396620813617, 'weighted_precision': 0.933975027354572, 'weighted_recall': 0.9395046518543694, 'weighted_f1': 0.9343115739178682}\n",
      "Validation Results\n",
      "{'acc': 0.9005816819481416, 'mean_precision': 0.4903357918685158, 'mean_recall': 0.36876920970764165, 'macro_f1': 0.41106954979970306, 'weighted_precision': 0.8875220170616794, 'weighted_recall': 0.9005816819481416, 'weighted_f1': 0.8905355695071234}\n",
      "{'acc': 0.9005816819481416, 'mean_precision': 0.4903357918685158, 'mean_recall': 0.36876920970764165, 'macro_f1': 0.41106954979970306, 'weighted_precision': 0.8875220170616794, 'weighted_recall': 0.9005816819481416, 'weighted_f1': 0.8905355695071234}\n",
      "New best model 0.90\n",
      "EPOCH 4\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9675007434470453, 'mean_precision': 0.6390906240743905, 'mean_recall': 0.6038165067861655, 'macro_f1': 0.618988764608433, 'weighted_precision': 0.9659538627720621, 'weighted_recall': 0.9675007434470453, 'weighted_f1': 0.966231296554775}\n",
      "Validation Results\n",
      "{'acc': 0.9127477077787637, 'mean_precision': 0.4925852117683451, 'mean_recall': 0.44067411726109595, 'macro_f1': 0.4625737419028773, 'weighted_precision': 0.9096272742762649, 'weighted_recall': 0.9127477077787637, 'weighted_f1': 0.9100725985860127}\n",
      "{'acc': 0.9127477077787637, 'mean_precision': 0.4925852117683451, 'mean_recall': 0.44067411726109595, 'macro_f1': 0.4625737419028773, 'weighted_precision': 0.9096272742762649, 'weighted_recall': 0.9127477077787637, 'weighted_f1': 0.9100725985860127}\n",
      "New best model 0.91\n",
      "EPOCH 5\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9819448574705807, 'mean_precision': 0.6822787027359921, 'mean_recall': 0.6654288105255638, 'macro_f1': 0.6735318936068581, 'weighted_precision': 0.9815296222081982, 'weighted_recall': 0.9819448574705807, 'weighted_f1': 0.9816664912741038}\n",
      "Validation Results\n",
      "{'acc': 0.9153702060534359, 'mean_precision': 0.5068952558989236, 'mean_recall': 0.44124520286898866, 'macro_f1': 0.46853218103815664, 'weighted_precision': 0.9084597333287312, 'weighted_recall': 0.9153702060534359, 'weighted_f1': 0.9107287960433853}\n",
      "{'acc': 0.9153702060534359, 'mean_precision': 0.5068952558989236, 'mean_recall': 0.44124520286898866, 'macro_f1': 0.46853218103815664, 'weighted_precision': 0.9084597333287312, 'weighted_recall': 0.9153702060534359, 'weighted_f1': 0.9107287960433853}\n",
      "New best model 0.92\n",
      "EPOCH 6\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9899740855601342, 'mean_precision': 0.7140524266234367, 'mean_recall': 0.7006978422342524, 'macro_f1': 0.7072211912486921, 'weighted_precision': 0.9898592598719765, 'weighted_recall': 0.9899740855601342, 'weighted_f1': 0.9898990733936563}\n",
      "Validation Results\n",
      "{'acc': 0.9078773538400867, 'mean_precision': 0.4721335471978603, 'mean_recall': 0.445418193719763, 'macro_f1': 0.44755073369775933, 'weighted_precision': 0.9085385674752005, 'weighted_recall': 0.9078773538400867, 'weighted_f1': 0.9054252809741837}\n",
      "{'acc': 0.9078773538400867, 'mean_precision': 0.4721335471978603, 'mean_recall': 0.445418193719763, 'macro_f1': 0.44755073369775933, 'weighted_precision': 0.9085385674752005, 'weighted_recall': 0.9078773538400867, 'weighted_f1': 0.9054252809741837}\n",
      "EPOCH 7\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9946046985853265, 'mean_precision': 0.7250549510429875, 'mean_recall': 0.7245327405975734, 'macro_f1': 0.7246380507505163, 'weighted_precision': 0.9946062546970221, 'weighted_recall': 0.9946046985853265, 'weighted_f1': 0.9945843056815288}\n",
      "Validation Results\n",
      "{'acc': 0.9076210194222617, 'mean_precision': 0.5288146173274983, 'mean_recall': 0.4305818520241084, 'macro_f1': 0.46389382246952704, 'weighted_precision': 0.9085871624798784, 'weighted_recall': 0.9076210194222617, 'weighted_f1': 0.9049471962094741}\n",
      "{'acc': 0.9076210194222617, 'mean_precision': 0.5288146173274983, 'mean_recall': 0.4305818520241084, 'macro_f1': 0.46389382246952704, 'weighted_precision': 0.9085871624798784, 'weighted_recall': 0.9076210194222617, 'weighted_f1': 0.9049471962094741}\n",
      "EPOCH 8\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9970686945069884, 'mean_precision': 0.7421435406965067, 'mean_recall': 0.7355861736056353, 'macro_f1': 0.7388350054919122, 'weighted_precision': 0.9970580004342506, 'weighted_recall': 0.9970686945069884, 'weighted_f1': 0.9970593887548937}\n",
      "Validation Results\n",
      "{'acc': 0.9174997535245982, 'mean_precision': 0.5002063031950891, 'mean_recall': 0.4827032147270213, 'macro_f1': 0.48983710054467827, 'weighted_precision': 0.915291934404395, 'weighted_recall': 0.9174997535245982, 'weighted_f1': 0.9159098490700731}\n",
      "{'acc': 0.9174997535245982, 'mean_precision': 0.5002063031950891, 'mean_recall': 0.4827032147270213, 'macro_f1': 0.48983710054467827, 'weighted_precision': 0.915291934404395, 'weighted_recall': 0.9174997535245982, 'weighted_f1': 0.9159098490700731}\n",
      "New best model 0.92\n",
      "EPOCH 9\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.998598071285951, 'mean_precision': 0.7428381779296477, 'mean_recall': 0.7428593107945108, 'macro_f1': 0.742842195204052, 'weighted_precision': 0.9986008631852796, 'weighted_recall': 0.998598071285951, 'weighted_f1': 0.9985983460934416}\n",
      "Validation Results\n",
      "{'acc': 0.9153504880212955, 'mean_precision': 0.5135695938044139, 'mean_recall': 0.4696664655199076, 'macro_f1': 0.4879542418775335, 'weighted_precision': 0.911457330477688, 'weighted_recall': 0.9153504880212955, 'weighted_f1': 0.9125186882391483}\n",
      "{'acc': 0.9153504880212955, 'mean_precision': 0.5135695938044139, 'mean_recall': 0.4696664655199076, 'macro_f1': 0.4879542418775335, 'weighted_precision': 0.911457330477688, 'weighted_recall': 0.9153504880212955, 'weighted_f1': 0.9125186882391483}\n",
      "EPOCH 10\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9988529674157781, 'mean_precision': 0.7443211166729832, 'mean_recall': 0.7444194984696777, 'macro_f1': 0.7443677947737083, 'weighted_precision': 0.9988538541257197, 'weighted_recall': 0.9988529674157781, 'weighted_f1': 0.9988528157788469}\n",
      "Validation Results\n",
      "{'acc': 0.9135758651286602, 'mean_precision': 0.5172966476437584, 'mean_recall': 0.459948574449124, 'macro_f1': 0.4833989489961923, 'weighted_precision': 0.9115535982765005, 'weighted_recall': 0.9135758651286602, 'weighted_f1': 0.910847695341476}\n",
      "{'acc': 0.9135758651286602, 'mean_precision': 0.5172966476437584, 'mean_recall': 0.459948574449124, 'macro_f1': 0.4833989489961923, 'weighted_precision': 0.9115535982765005, 'weighted_recall': 0.9135758651286602, 'weighted_f1': 0.910847695341476}\n",
      "EPOCH 11\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9996601384935638, 'mean_precision': 0.7482154416927607, 'mean_recall': 0.7489553088945473, 'macro_f1': 0.7485831651966169, 'weighted_precision': 0.9996606573592576, 'weighted_recall': 0.9996601384935638, 'weighted_f1': 0.9996601753367165}\n",
      "Validation Results\n",
      "{'acc': 0.9144237405106971, 'mean_precision': 0.517828912853891, 'mean_recall': 0.46786796063163744, 'macro_f1': 0.48944377857478844, 'weighted_precision': 0.9109120467968216, 'weighted_recall': 0.9144237405106971, 'weighted_f1': 0.9114387154317902}\n",
      "{'acc': 0.9144237405106971, 'mean_precision': 0.517828912853891, 'mean_recall': 0.46786796063163744, 'macro_f1': 0.48944377857478844, 'weighted_precision': 0.9109120467968216, 'weighted_recall': 0.9144237405106971, 'weighted_f1': 0.9114387154317902}\n",
      "EPOCH 12\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9997026211818684, 'mean_precision': 0.7489580107001158, 'mean_recall': 0.7491668517316658, 'macro_f1': 0.7490607342135019, 'weighted_precision': 0.9997031479406382, 'weighted_recall': 0.9997026211818684, 'weighted_f1': 0.999702657913183}\n",
      "Validation Results\n",
      "{'acc': 0.9071083505866114, 'mean_precision': 0.5204532267859032, 'mean_recall': 0.43062100380119966, 'macro_f1': 0.46537822865055084, 'weighted_precision': 0.90056348730248, 'weighted_recall': 0.9071083505866114, 'weighted_f1': 0.8999614218456766}\n",
      "{'acc': 0.9071083505866114, 'mean_precision': 0.5204532267859032, 'mean_recall': 0.43062100380119966, 'macro_f1': 0.46537822865055084, 'weighted_precision': 0.90056348730248, 'weighted_recall': 0.9071083505866114, 'weighted_f1': 0.8999614218456766}\n",
      "EPOCH 13\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9997875865584774, 'mean_precision': 0.7494366368124193, 'mean_recall': 0.7494018791139933, 'macro_f1': 0.7494191869309347, 'weighted_precision': 0.9997876324361106, 'weighted_recall': 0.9997875865584774, 'weighted_f1': 0.9997875821229629}\n",
      "Validation Results\n",
      "{'acc': 0.9126491176180617, 'mean_precision': 0.5203973273406283, 'mean_recall': 0.4554602129481418, 'macro_f1': 0.48204375648892056, 'weighted_precision': 0.9079574693557422, 'weighted_recall': 0.9126491176180617, 'weighted_f1': 0.9082083252755786}\n",
      "{'acc': 0.9126491176180617, 'mean_precision': 0.5203973273406283, 'mean_recall': 0.4554602129481418, 'macro_f1': 0.48204375648892056, 'weighted_precision': 0.9079574693557422, 'weighted_recall': 0.9126491176180617, 'weighted_f1': 0.9082083252755786}\n",
      "EPOCH 14\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9999575173116955, 'mean_precision': 0.7497605363984675, 'mean_recall': 0.7498482088646022, 'macro_f1': 0.7498041311709066, 'weighted_precision': 0.999957639388386, 'weighted_recall': 0.9999575173116955, 'weighted_f1': 0.9999575285116592}\n",
      "Validation Results\n",
      "{'acc': 0.9156462585034013, 'mean_precision': 0.5246174546736821, 'mean_recall': 0.46327648312384756, 'macro_f1': 0.48799924893405816, 'weighted_precision': 0.9106618301076934, 'weighted_recall': 0.9156462585034013, 'weighted_f1': 0.9116594115783114}\n",
      "{'acc': 0.9156462585034013, 'mean_precision': 0.5246174546736821, 'mean_recall': 0.46327648312384756, 'macro_f1': 0.48799924893405816, 'weighted_precision': 0.9106618301076934, 'weighted_recall': 0.9156462585034013, 'weighted_f1': 0.9116594115783114}\n",
      "EPOCH 15\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9996601384935638, 'mean_precision': 0.74849278469982, 'mean_recall': 0.7482189821949902, 'macro_f1': 0.7483542296420881, 'weighted_precision': 0.9996599527524251, 'weighted_recall': 0.9996601384935638, 'weighted_f1': 0.9996598051821883}\n",
      "Validation Results\n",
      "{'acc': 0.9057872424332052, 'mean_precision': 0.4867895830448741, 'mean_recall': 0.4470686036718868, 'macro_f1': 0.46219063400753974, 'weighted_precision': 0.9051211437229789, 'weighted_recall': 0.9057872424332052, 'weighted_f1': 0.9038575144397998}\n",
      "{'acc': 0.9057872424332052, 'mean_precision': 0.4867895830448741, 'mean_recall': 0.4470686036718868, 'macro_f1': 0.46219063400753974, 'weighted_precision': 0.9051211437229789, 'weighted_recall': 0.9057872424332052, 'weighted_f1': 0.9038575144397998}\n",
      "EPOCH 16\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9980457963379923, 'mean_precision': 0.7459561770585434, 'mean_recall': 0.7422252736695375, 'macro_f1': 0.7440734963126716, 'weighted_precision': 0.9980422553997661, 'weighted_recall': 0.9980457963379923, 'weighted_f1': 0.9980408127811999}\n",
      "Validation Results\n",
      "{'acc': 0.9078773538400867, 'mean_precision': 0.4912281684049861, 'mean_recall': 0.454919861372537, 'macro_f1': 0.46649386061529136, 'weighted_precision': 0.9060345267314833, 'weighted_recall': 0.9078773538400867, 'weighted_f1': 0.904796844958272}\n",
      "{'acc': 0.9078773538400867, 'mean_precision': 0.4912281684049861, 'mean_recall': 0.454919861372537, 'macro_f1': 0.46649386061529136, 'weighted_precision': 0.9060345267314833, 'weighted_recall': 0.9078773538400867, 'weighted_f1': 0.904796844958272}\n",
      "EPOCH 17\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9994477250520413, 'mean_precision': 0.7483285511405794, 'mean_recall': 0.7478139216847155, 'macro_f1': 0.7480654538322007, 'weighted_precision': 0.9994482782630439, 'weighted_recall': 0.9994477250520413, 'weighted_f1': 0.9994475577697263}\n",
      "Validation Results\n",
      "{'acc': 0.9103421078576358, 'mean_precision': 0.49295355042875655, 'mean_recall': 0.46368851954842977, 'macro_f1': 0.47400765502148995, 'weighted_precision': 0.908241333963285, 'weighted_recall': 0.9103421078576358, 'weighted_f1': 0.9085461221674501}\n",
      "{'acc': 0.9103421078576358, 'mean_precision': 0.49295355042875655, 'mean_recall': 0.46368851954842977, 'macro_f1': 0.47400765502148995, 'weighted_precision': 0.908241333963285, 'weighted_recall': 0.9103421078576358, 'weighted_f1': 0.9085461221674501}\n",
      "EPOCH 18\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9999150346233909, 'mean_precision': 0.7498438724263793, 'mean_recall': 0.7498438724263793, 'macro_f1': 0.7498438724263793, 'weighted_precision': 0.9999150346233909, 'weighted_recall': 0.9999150346233909, 'weighted_f1': 0.9999150346233909}\n",
      "Validation Results\n",
      "{'acc': 0.9110716750468303, 'mean_precision': 0.4879588179244439, 'mean_recall': 0.4732355055804723, 'macro_f1': 0.4768963541031697, 'weighted_precision': 0.9121386526810568, 'weighted_recall': 0.9110716750468303, 'weighted_f1': 0.9102906196320706}\n",
      "{'acc': 0.9110716750468303, 'mean_precision': 0.4879588179244439, 'mean_recall': 0.4732355055804723, 'macro_f1': 0.4768963541031697, 'weighted_precision': 0.9121386526810568, 'weighted_recall': 0.9110716750468303, 'weighted_f1': 0.9102906196320706}\n",
      "EPOCH 19\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9999150346233909, 'mean_precision': 0.7498441484102617, 'mean_recall': 0.7494545380206513, 'macro_f1': 0.7496483929703105, 'weighted_precision': 0.9999151118646424, 'weighted_recall': 0.9999150346233909, 'weighted_f1': 0.9999149847612284}\n",
      "Validation Results\n",
      "{'acc': 0.9063393473331361, 'mean_precision': 0.47281194561690754, 'mean_recall': 0.4685326432472617, 'macro_f1': 0.4616401466016867, 'weighted_precision': 0.9112186276902017, 'weighted_recall': 0.9063393473331361, 'weighted_f1': 0.9068318350099438}\n",
      "{'acc': 0.9063393473331361, 'mean_precision': 0.47281194561690754, 'mean_recall': 0.4685326432472617, 'macro_f1': 0.4616401466016867, 'weighted_precision': 0.9112186276902017, 'weighted_recall': 0.9063393473331361, 'weighted_f1': 0.9068318350099438}\n",
      "EPOCH 20\n",
      "=================================\n",
      "Training Results\n",
      "Model training:[*************************************************************************************************** ]99%{'acc': 0.9999575173116955, 'mean_precision': 0.7494623655913978, 'mean_recall': 0.7499956635617769, 'macro_f1': 0.7497281445615819, 'weighted_precision': 0.9999577913935555, 'weighted_recall': 0.9999575173116955, 'weighted_f1': 0.9999575855012245}\n",
      "Validation Results\n",
      "{'acc': 0.9140096618357488, 'mean_precision': 0.48759491237215175, 'mean_recall': 0.49099287576406264, 'macro_f1': 0.4884940664400608, 'weighted_precision': 0.914896942904755, 'weighted_recall': 0.9140096618357488, 'weighted_f1': 0.9143554565406062}\n",
      "{'acc': 0.9140096618357488, 'mean_precision': 0.48759491237215175, 'mean_recall': 0.49099287576406264, 'macro_f1': 0.4884940664400608, 'weighted_precision': 0.914896942904755, 'weighted_recall': 0.9140096618357488, 'weighted_f1': 0.9143554565406062}\n",
      "{'acc': 0.9162772355318939, 'mean_precision': 0.4961264630487687, 'mean_recall': 0.4784682203847632, 'macro_f1': 0.4853204975536378, 'weighted_precision': 0.9141549976519289, 'weighted_recall': 0.9162772355318939, 'weighted_f1': 0.9146715450130352}\n",
      "Final result\n",
      "{'acc': 0.9162772355318939, 'mean_precision': 0.4961264630487687, 'mean_recall': 0.4784682203847632, 'macro_f1': 0.4853204975536378, 'weighted_precision': 0.9141549976519289, 'weighted_recall': 0.9162772355318939, 'weighted_f1': 0.9146715450130352}\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9162772355318939"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2index = {l: i+1 for i, l in enumerate(r.labels)}\n",
    "label2index['[PAD]'] = 0\n",
    "label2index[START_TAG] = len(r.labels)+1\n",
    "label2index[STOP_TAG] = len(r.labels)+2\n",
    "\n",
    "\n",
    "\n",
    "model  = LSTMClassifier(embeddings, len(r.labels), embed_dim, 100,tag_to_ix=label2index,batch_size= 1, hidden_units=[100])\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Model has {num_params} parameters\")\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "loss = loss.to(device)\n",
    "\n",
    "learnable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(learnable_params,lr=0.001)\n",
    "# train_mini_set = train_dataset\n",
    "train_mini_set = train[:900]\n",
    "train_mini_set = TensorDataset(train_mini_set[0], train_mini_set[1],train_mini_set[2])\n",
    "fit(model, label2index.keys(), optimizer, loss, 20, 1, train_mini_set, valid, test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train_mini_set = train_dataset\n",
    "train_mini_set = train[:300]\n",
    "train_mini_set = TensorDataset(train_mini_set[0], train_mini_set[1],train_mini_set[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(test, batch_size=1, shuffle=True)\n",
    "log_interval = int(len(train_loader) * 0.01)\n",
    "for batch_idx, batch in enumerate(train_loader):\n",
    "\n",
    "    loss_value, y_pred, y_actual = update(model, loss, batch,optimizer)\n",
    "    # _, best = y_pred.max(1)\n",
    "    yt = y_actual.cpu().int().numpy()\n",
    "    yp = y_pred.cpu().int().numpy()\n",
    "    if batch_idx==0:\n",
    "        print(loss_value, y_pred, y_actual)\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x, lengths, y = train[0]\n",
    "print(x,lengths,y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "class ConfusionMatrix:\n",
    "    \"\"\"Confusion matrix with metrics\n",
    "\n",
    "    This class accumulates classification output, and tracks it in a confusion matrix.\n",
    "    Metrics are available that use the confusion matrix\n",
    "    \"\"\"\n",
    "    def __init__(self, labels):\n",
    "        \"\"\"Constructor with input labels\n",
    "\n",
    "        :param labels: Either a dictionary (`k=int,v=str`) or an array of labels\n",
    "        \"\"\"\n",
    "        if type(labels) is dict:\n",
    "            self.labels = []\n",
    "            for i in range(len(labels)):\n",
    "                self.labels.append(labels[i])\n",
    "        else:\n",
    "            self.labels = labels\n",
    "        nc = len(self.labels)\n",
    "        self._cm = np.zeros((nc, nc), dtype=np.int)\n",
    "\n",
    "    def add(self, truth, guess):\n",
    "        \"\"\"Add a single value to the confusion matrix based off `truth` and `guess`\n",
    "\n",
    "        :param truth: The real `y` value (or ground truth label)\n",
    "        :param guess: The guess for `y` value (or assertion)\n",
    "        \"\"\"\n",
    "\n",
    "        self._cm[truth, guess] += 1\n",
    "\n",
    "    def __str__(self):\n",
    "        values = []\n",
    "        width = max(8, max(len(x) for x in self.labels) + 1)\n",
    "        for i, label in enumerate([''] + self.labels):\n",
    "            values += [\"{:>{width}}\".format(label, width=width+1)]\n",
    "        values += ['\\n']\n",
    "        for i, label in enumerate(self.labels):\n",
    "            values += [\"{:>{width}}\".format(label, width=width+1)]\n",
    "            for j in range(len(self.labels)):\n",
    "                values += [\"{:{width}d}\".format(self._cm[i, j], width=width + 1)]\n",
    "            values += ['\\n']\n",
    "        values += ['\\n']\n",
    "        return ''.join(values)\n",
    "\n",
    "    def save(self, outfile):\n",
    "        ordered_fieldnames = OrderedDict([(\"labels\", None)] + [(l, None) for l in self.labels])\n",
    "        with open(outfile, 'w') as f:\n",
    "            dw = csv.DictWriter(f, delimiter=',', fieldnames=ordered_fieldnames)\n",
    "            dw.writeheader()\n",
    "            for index, row in enumerate(self._cm):\n",
    "                row_dict = {l: row[i] for i, l in enumerate(self.labels)}\n",
    "                row_dict.update({\"labels\": self.labels[index]})\n",
    "                dw.writerow(row_dict)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the matrix\n",
    "        \"\"\"\n",
    "        self._cm *= 0\n",
    "\n",
    "    def get_correct(self):\n",
    "        \"\"\"Get the diagonals of the confusion matrix\n",
    "\n",
    "        :return: (``int``) Number of correct classifications\n",
    "        \"\"\"\n",
    "        return self._cm.diagonal().sum()\n",
    "\n",
    "    def get_total(self):\n",
    "        \"\"\"Get total classifications\n",
    "\n",
    "        :return: (``int``) total classifications\n",
    "        \"\"\"\n",
    "        return self._cm.sum()\n",
    "\n",
    "    def get_acc(self):\n",
    "        \"\"\"Get the accuracy\n",
    "\n",
    "        :return: (``float``) accuracy\n",
    "        \"\"\"\n",
    "        return float(self.get_correct())/self.get_total()\n",
    "\n",
    "    def get_recall(self):\n",
    "        \"\"\"Get the recall\n",
    "\n",
    "        :return: (``float``) recall\n",
    "        \"\"\"\n",
    "        total = np.sum(self._cm, axis=1)\n",
    "        total = (total == 0) + total\n",
    "        return np.diag(self._cm) / total.astype(float)\n",
    "\n",
    "    def get_support(self):\n",
    "        return np.sum(self._cm, axis=1)\n",
    "\n",
    "    def get_precision(self):\n",
    "        \"\"\"Get the precision\n",
    "        :return: (``float``) precision\n",
    "        \"\"\"\n",
    "\n",
    "        total = np.sum(self._cm, axis=0)\n",
    "        total = (total == 0) + total\n",
    "        return np.diag(self._cm) / total.astype(float)\n",
    "\n",
    "    def get_mean_precision(self):\n",
    "        \"\"\"Get the mean precision across labels\n",
    "\n",
    "        :return: (``float``) mean precision\n",
    "        \"\"\"\n",
    "        return np.mean(self.get_precision())\n",
    "\n",
    "    def get_weighted_precision(self):\n",
    "        return np.sum(self.get_precision() * self.get_support())/float(self.get_total())\n",
    "\n",
    "    def get_mean_recall(self):\n",
    "        \"\"\"Get the mean recall across labels\n",
    "\n",
    "        :return: (``float``) mean recall\n",
    "        \"\"\"\n",
    "        return np.mean(self.get_recall())\n",
    "\n",
    "    def get_weighted_recall(self):\n",
    "        return np.sum(self.get_recall() * self.get_support())/float(self.get_total())\n",
    "\n",
    "    def get_weighted_f(self, beta=1):\n",
    "        return np.sum(self.get_class_f(beta) * self.get_support())/float(self.get_total())\n",
    "\n",
    "    def get_macro_f(self, beta=1):\n",
    "        \"\"\"Get the macro F_b, with adjustable beta (defaulting to F1)\n",
    "\n",
    "        :param beta: (``float``) defaults to 1 (F1)\n",
    "        :return: (``float``) macro F_b\n",
    "        \"\"\"\n",
    "        if beta < 0:\n",
    "            raise Exception('Beta must be greater than 0')\n",
    "        return np.mean(self.get_class_f(beta))\n",
    "\n",
    "    def get_class_f(self, beta=1):\n",
    "        p = self.get_precision()\n",
    "        r = self.get_recall()\n",
    "\n",
    "        b = beta*beta\n",
    "        d = (b * p + r)\n",
    "        d = (d == 0) + d\n",
    "\n",
    "        return (b + 1) * p * r / d\n",
    "\n",
    "    def get_f(self, beta=1):\n",
    "        \"\"\"Get 2 class F_b, with adjustable beta (defaulting to F1)\n",
    "\n",
    "        :param beta: (``float``) defaults to 1 (F1)\n",
    "        :return: (``float``) 2-class F_b\n",
    "        \"\"\"\n",
    "        p = self.get_precision()[1]\n",
    "        r = self.get_recall()[1]\n",
    "        if beta < 0:\n",
    "            raise Exception('Beta must be greater than 0')\n",
    "        d = (beta*beta * p + r)\n",
    "        if d == 0:\n",
    "            return 0\n",
    "        return (beta*beta + 1) * p * r / d\n",
    "\n",
    "    def get_all_metrics(self):\n",
    "        \"\"\"Make a map of metrics suitable for reporting, keyed by metric name\n",
    "\n",
    "        :return: (``dict``) Map of metrics keyed by metric names\n",
    "        \"\"\"\n",
    "        metrics = {'acc': self.get_acc()}\n",
    "        # If 2 class, assume second class is positive AKA 1\n",
    "        if len(self.labels) == 2:\n",
    "            metrics['precision'] = self.get_precision()[1]\n",
    "            metrics['recall'] = self.get_recall()[1]\n",
    "            metrics['f1'] = self.get_f(1)\n",
    "        else:\n",
    "            metrics['mean_precision'] = self.get_mean_precision()\n",
    "            metrics['mean_recall'] = self.get_mean_recall()\n",
    "            metrics['macro_f1'] = self.get_macro_f(1)\n",
    "            metrics['weighted_precision'] = self.get_weighted_precision()\n",
    "            metrics['weighted_recall'] = self.get_weighted_recall()\n",
    "            metrics['weighted_f1'] = self.get_weighted_f(1)\n",
    "        return metrics\n",
    "\n",
    "    def add_batch(self, truth, guess):\n",
    "        \"\"\"Add a batch of data to the confusion matrix\n",
    "\n",
    "        :param truth: The truth tensor\n",
    "        :param guess: The guess tensor\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for truth_i, guess_i in zip(truth, guess):\n",
    "            self.add(truth_i, guess_i)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cm.get_all_metrics()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class Trainer:\n",
    "    def __init__(self, optimizer: torch.optim.Optimizer):\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def run(self, model, labels, train, loss, batch_size):\n",
    "        model.train()\n",
    "        train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        cm = ConfusionMatrix(labels)\n",
    "\n",
    "        for batch in train_loader:\n",
    "            loss_value, y_pred, y_actual = self.update(model, loss, batch)\n",
    "            _, best = y_pred.max(1)\n",
    "            yt = y_actual.cpu().int().numpy()\n",
    "            yp = best.cpu().int().numpy()\n",
    "            cm.add_batch(yt, yp)\n",
    "\n",
    "        print(cm.get_all_metrics())\n",
    "        return cm\n",
    "\n",
    "    def update(self, model, loss, batch):\n",
    "        self.optimizer.zero_grad()\n",
    "        x, lengths, y = batch\n",
    "        lengths, perm_idx = lengths.sort(0, descending=True)\n",
    "        x_sorted = x[perm_idx]\n",
    "        y_sorted = y[perm_idx]\n",
    "        y_sorted = y_sorted.to('cuda:0')\n",
    "        inputs = (x_sorted.to('cuda:0'), lengths)\n",
    "        y_pred = model(inputs)\n",
    "        loss_value = loss(y_pred, y_sorted)\n",
    "        loss_value.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss_value.item(), y_pred, y_sorted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fit(model, labels, optimizer, loss, epochs, batch_size, train, valid, test):\n",
    "\n",
    "    trainer = Trainer(optimizer)\n",
    "    # evaluator = Evaluator()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('EPOCH {}'.format(epoch + 1))\n",
    "        print('=================================')\n",
    "        print('Training Results')\n",
    "        cm = trainer.run(model, labels, train, loss, batch_size)\n",
    "    #     print('Validation Results')\n",
    "    #     cm = evaluator.run(model, labels, valid)\n",
    "    #     print(cm.get_all_metrics())\n",
    "    #     if cm.get_acc() > best_acc:\n",
    "    #         print('New best model {:.2f}'.format(cm.get_acc()))\n",
    "    #         best_acc = cm.get_acc()\n",
    "    #         torch.save(model.state_dict(), './checkpoint.pth')\n",
    "    # if test:\n",
    "    #     model.load_state_dict(torch.load('./checkpoint.pth'))\n",
    "    #     cm = evaluator.run(model, labels, test)\n",
    "    #     print('Final result')\n",
    "    #     print(cm.get_all_metrics())\n",
    "    return cm.get_acc()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model  = LSTMClassifier(embeddings, len(r.labels), embed_dim, 100, hidden_units=[100])\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Model has {num_params} parameters\")\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "loss = loss.to(device)\n",
    "\n",
    "learnable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(learnable_params,lr=1.0)\n",
    "\n",
    "fit(model, r.labels, optimizer, loss, 5, 50, train, valid, test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = torch.tensor([[1,2,3,0,0],\n",
    "                     [4,5,0,0,0],\n",
    "                     [6,7,8,9,0]])\n",
    "mask = (data != 0)\n",
    "print(mask)\n",
    "valid = (mask.sum(dim=1))\n",
    "print(valid)\n",
    "data[mask].split(valid.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[922, 42120, 1837, 346, 257, 1303, 751, 1341, 1842]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(VALID,delimiter='\\t',names=['Word','POS','NP','NER'],skiprows=[0])\n",
    "df=df.dropna()\n",
    "tags=set(df.NER.to_list())\n",
    "num_tag= {}\n",
    "for tag in tags:\n",
    "    num=df.NER.loc[df.NER==tag].count()\n",
    "    num_tag[tag]=num\n",
    "print(list(num_tag.values()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x396 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "image/png": {
       "width": 502,
       "height": 344
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(range(len(tags)), list(num_tag.values()), height=0.7, color='steelblue',alpha=0.8)\n",
    "plt.yticks(range(len(tags)), list(num_tag.keys()))\n",
    "plt.title(\"The distribution of NEG labels on dev dataset\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}